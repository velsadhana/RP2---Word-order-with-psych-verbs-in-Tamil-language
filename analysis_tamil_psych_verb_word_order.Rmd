---
title: "analysis_tamil_psych_verb_word_order"
author: "Sadhana"
date: "2023-08-09"
output: html_document
---

# Loading and updating the psych verbs dataset 
## 1. Loading the necessary libraries


```{r libraries, message=FALSE, warning=FALSE}

library(tidyverse)
library(broom)
library(Hmisc)
library(lme4)

```

## 2. Loading the annotation file into R 

```{r}

tamil.psych.verb.df <- read.csv2(file.choose())

```

## 3. Removing the unwanted columns

```{r}

tamil.psych.verb.df <- select(tamil.psych.verb.df, -c(Sentence, Case_of_subject_inTamil, Case_of_object_inTamil, Psych))

```

## 4. Renaming the 'EO...ES' column

```{r}

tamil.psych.verb.df <- rename(tamil.psych.verb.df, EO_ES = EO...ES)

```

## 5. Removing white spaces from the column values

```{r}

tamil.psych.verb.df <- mutate_if(tamil.psych.verb.df, is.character, str_trim)

```
 
## 6. Updating the column values of 'Case_of_object' column
 
```{r}

tamil.psych.verb.df <- mutate(tamil.psych.verb.df, Case_of_object = replace(Case_of_object, Case_of_object == 'accusative (phrasal)','accusative'))

tamil.psych.verb.df <- mutate(tamil.psych.verb.df, Case_of_object = replace(Case_of_object, Case_of_object == 'dative (phrasal)','dative'))

tamil.psych.verb.df <- mutate(tamil.psych.verb.df, Case_of_object = replace(Case_of_object, Case_of_object %in% c( 'dative participle noun clause', 'accusative participle noun clause'),'participle noun clause'))

tamil.psych.verb.df <- mutate(tamil.psych.verb.df, Case_of_object = replace(Case_of_object, Case_of_object %in% c("special verbal participle 'aai'","special verbal participle 'endru'", "special verbal participle 'aaga'", "special verbal participle 'patri'","special verbal participle 'ena'", "special negative verbal participle 'indri'","special negative verbal participle 'illaamal'"),'special verbal participle'))

tamil.psych.verb.df <- mutate(tamil.psych.verb.df, Case_of_object = replace(Case_of_object, Case_of_object == 'negative verbal participle clause','verbal participle clause'))


```
 
 
```{r}
table (tamil.psych.verb.df$Case_of_object)
```


## 7. Converting all the character columns as well as ID column into factors 

```{r}

tamil.psych.verb.df <- tamil.psych.verb.df %>% mutate_if(is.character, as.factor) %>% mutate_at(c('ID'), as.factor)

```

## 8. Converting integer column values into logarithmic values by adding new columns

```{r}

tamil.psych.verb.df <- mutate(tamil.psych.verb.df, log_syllable_subject = log(Syllable_of_subject), log_syllable_object = log(Syllable_of_object))

```


## 9. Checking the structure of the dataframe

```{r}

str(tamil.psych.verb.df)

```

```{r}

summary (tamil.psych.verb.df)

```

## 10. Checking the no.of data for each psych verb

```{r}

table (tamil.psych.verb.df$Verb)

```

## 11. Checking the no. of data for SOV and OSV order

```{r}

table (tamil.psych.verb.df$Word_order)


ggplot(tamil.psych.verb.df, aes(x = Word_order)) +
  geom_bar(stat = "count", aes(fill = Word_order)) +
  labs(x = "word order", y = "Frequency of word order")

```

## 12. Checking the word order against the syllabe of subject and object

```{r}
 
tamil.psych.verb.df %>% group_by(Word_order) %>% summarise(across(c(Syllable_of_subject, Syllable_of_object), mean))

```


# Model 1: Generalized Linear Model (GLM)

When the response variable is a categorical variable, then GLM will be used. In GLM, the categorical response variable is modeled as a function of one or more predictors that can be either categorical or continuous values. GLM observes the probability of a single event of response variable. 

## Creating model 1

```{r}

#tamil.psych.verb.glm <- glm(Word_order ~ EO_ES + Case_of_subject + Case_of_object + Animacy_of_subject + Animacy_of_object + Pronoun_subject + Pronoun_object + log_syllable_subject + log_syllable_object, family ="binomial", data = tamil.psych.verb.df)

tamil.psych.verb.glm1 <- glm(Word_order ~ EO_ES + Case_of_subject + Case_of_object + log_syllable_subject + log_syllable_object, family ="binomial", data = tamil.psych.verb.df)



```



```{r}

anova(tamil.psych.verb.glm1, tamil.psych.verb.glm, test = "Chisq")

```


This 'tamil.psych.glm1' is the GLM model. The response variable is a Word_order that is binomial as it has 2 values namely 'SOV' and 'OSV'. The predictors are EO_ES, Case_of_subject, Case_of_object, log_syllable_subject and log_syllable_object. Phrasal_subject and Clausal_object are not added to the predictors as they are  correlating with the  Case_of_subject and Case_of_object. Similarly animacy, pronouns and focus are also not added, since adding these variables decreasing the significance of the model as well as  they doesn't have strong affect on the word order. It is further confirmed by the anova test, that is used to compare the models. Anova test compared our actual model with the other complex model (tamil.psych.verb.glm) which contains animacy, pronouns and focus. The resultant p-value tells about the efficiency of complex model. If p-value is <0.05, then the complex model is significant or else it is not significant. The p-value for this test is 0.73 that is >0.05. This shows that the complex model is not at all significant. Moreover, adding the animacy, pronouns and focus as predictors will worsen the model. Thus, tamil.psych.glm1 model has chosen finally.


```{r}

summary(tamil.psych.verb.glm1)

```


Calculating the probabilities for SOV.

```{r}

intercept <- tidy(tamil.psych.verb.glm1)$estimate[1]
print ("Probability of SOV order with reference levels")
plogis(intercept)

slope_verb_participle <- tidy(tamil.psych.verb.glm1)$estimate[10]
print ("Probability of SOV order with verbal participle clause")
plogis(intercept + slope_verb_participle * 1)

slope_adverbial_clause <- tidy(tamil.psych.verb.glm1)$estimate[4]
print ("Probability of SOV order with adverbial clause")
plogis(intercept + slope_adverbial_clause * 1)



```

Calculating the probabilities for OSV. 

```{r}

print ("Probability of OSV order with reference levels")
1-plogis(intercept)

print ("Probability of OSV order with adverbial clause")
1 - plogis(intercept + slope_adverbial_clause * 1)

print ("Probability of OSV order with verbal participle clause")
1 - plogis(intercept + slope_verb_participle * 1)

```

Checking the reference levels.

```{r}

print ("Reference level for word order")
levels (tamil.psych.verb.df$Word_order)

print ("Reference level for EO_ES")
levels (tamil.psych.verb.df$EO_ES)

print ("Reference level for case of subject")
levels (tamil.psych.verb.df$Case_of_subject)

print ("Reference level for case of object")
levels (tamil.psych.verb.df$Case_of_object)

```


## Interpretation of model 1:

The output of model 1 provides the intercept and slopes values. The values are the log odds(logits) that has to be converted into a probability value. The category shown to the right is taken as the reference level for the response variable. Thus, SOV is the reference level for Word_order. The category which occurs first in the alphabetical order is taken as the reference level for predictors. For e.g., accusative is the reference level for Case_of_object.

The positive slope is the indication of increase in the SOV order and the negative slope decreases the SOV order. For e.g., the ES and the nominative (phrasal) category has positive slope values. It means the odds of observing SOV increases when the verb is ES and subject is phrasal. Likewise, the infinite verbal participle and verbal participle clause are positives, meaning the SOV is more for these cases of object. The adverbial clause has a negative slope, which means the SOV order is less for this. Despite of positive and negative slopes, it is worth to consider only the predictors those having significant p-values.

Predictors having p-value <0.05 are considered to be significant predictors and has a strong affect with the word order. Predictors such as adverbial clause, infinite verbal participle, participle noun clause and special verbal participle are medium significant (*).The intercept is also medium significant.
Predictors such as verbal participle clause, syllable of subject and syllable of object are highly significant (***). When the syllable of subject increases, the odds of observing SOV highly increases and when the syllable of object increases, the SOV decreases. 

The probability of SOV is 71% and OSV is 29% with the reference levels namely EO verb, nominative subject and accusative object. The probability of SOV for verbal participle clause is 85% which is the highest among predictors next to subject syllable.The probability of SOV for adverbial clause is 48% which is the lowest among predictors. It means the verbal participle clause and lengthy subject has a great tendency towards SOV and the adverbial clause and lengthy object a great tendency towards OSV. Overall, the probability of observing SOV is higher than OSV.


## Plotting the predictions of model 1 using ggplot

```{r}

tamil.psych.verb.df <- mutate(tamil.psych.verb.df, Word_order1 = ifelse(Word_order =='SOV', 1, 0))

tamil.psych.verb.df$pred_model1 <- predict(tamil.psych.verb.glm1, type = "response")


ggplot(tamil.psych.verb.df, aes(x = ID, y = Word_order1, group = 1)) + 
  geom_point(aes(color = "red")) +
  geom_smooth(aes(y=pred_model1)) +
  labs(x = "no. of data", y = "actual vs predict values")


```

In above graph, x-axis is the total no. of data, that is from 1 to 1412 and y-axis is probability value from 0 to 1. The lower red dots (it looks like line in the graph due to congestion) refers to the actual OSV word order and upper one refers to SOV word order in dataset. The blue curve indicates the model's predicted probabilities for the word order being SOV. It shows that the average probability for SOV is above 0.5 i.e., more than 50%


## Evaluation of model 1

```{r}

options(scipen = 999)
somers2(tamil.psych.verb.df$pred_model1, tamil.psych.verb.df$Word_order1)


```

The concordance index C is used to measure the goodness of fit of logistic regression model. When the C value is >= 0.9, model has outstanding discrimination. If 0.8 ≤ C < 0.9, then excellent discrimination. If 0.7 ≤ C < 0.8, acceptable discrimination. if C = 0.5, then no discrimination. As the C value for this model is 0.9,  it shows that the model discriminates well and is a good fit for the data. It means for 90% of the pairs of SOV and OSV sentences, the probability of predicting SOV sentences is higher than OSV sentences.


# Model 2: Generalized Linear Mixed Model (GLMM)

Generally, there are chances that two or more data points are connected to each other. For e.g., in a survey data, two data points might come from the same person and these data points works in a similar way as they belongs to the same person. Independent assumptions are violated if data points are dependent. For Linear Model (LM) and Generalized Linear Model (GLM), data points are assumed to be independent of each other. In model 1 (GLM), the independent assumption has been violated as the data points are dependent to each other in terms of verb. Even though the verb was not added as a predictor in model1, this assumption is still not satisfied. 

In fact, the data points for this data set were collected based on the verbs. There are totally 10 psych verbs here. Multiple data points belongs to the same verb. Those data which contains the same verb might have a similar grammatical syntax and functionality. It might be plausible that verb has an influence on the word order. Hence, it is necessary to include the verb in a model in order to determine whether it affects the word order or not. For e.g., the below result shows the verb தவி (thavi - to suffer) prefers more SOV order and the verb அஞ்சு (anju - to fear) prefers more OSV order. In addition to verb, one can also categorize the data points based on the type Experiencer Object (EO) and Experiencer Subject (ES) and this too might have an influence on the word order.  Besides, it is important to determine whether the effects of verbal participle, adverbial clause, syllable of subject and object are still hold even after the word order are conditioned on verb and EO/ES.

It is impossible to apply LM and GLM model when verb is included. As the verb act as a dependent cluster, it will violate the independent assumption. At this point GLMM comes into picture. It is used for analyzing the data that are dependent to each other. In GLMM, the predictors to which data points are dependent are known as 'random effects'. The other predictors are called 'fixed effects'. The random effect should be categorical, while they account for the cluster dependency and the fixed effect can be categorical or numerical.

## Checking data count for each verb against the word order

```{r}

tamil.psych.verb.df %>% group_by(Verb ,Word_order) %>% summarise(Count = n()) %>% arrange(desc(Count))

```

## Creating model 2:

```{r}

tamil.psych.verb.glmm <- glmer(Word_order ~ Case_of_subject + Case_of_object + log_syllable_subject + log_syllable_object + (1 | Verb)+ (1 | EO_ES), family ="binomial", data = tamil.psych.verb.df)

```

The 'tamil.psych.verb.glmm' is the GLMM model. It consists of 2 random effect components i.e., (1 | Verb) and (1 | EO_ES) and fixed effects such as Case_of_subject + Case_of_object + log_syllable_subject + log_syllable_object. The fixed effects are same as the predictors of model 1 except EO_ES, while it is considered as random effect in this model. The symbol '|' means 'conditioned on'.  For e.g., the expression (1 | Verb) expresses that the word order is conditioned by verb as random intercept and 1 is the placeholder for intercept. Hence in this model, the word order is conditioned by verb random intercept and by EO_ES random intercept. In a way, this model is two random intercept model. The random slope estimates the variation between verbs and this variation is not relevant for this analysis. So, there is no random slope for this model.

```{r}

summary (tamil.psych.verb.glmm)

```

Calculate the probabilities for SOV

```{r}

print ("Probability of SOV order with reference levels")
plogis(1.32)

print ("Probability of SOV order with adverbial clause")
plogis(-1.43)


```

Calculate the probabilities for OSV

```{r}

print ("Probability of OSV order with reference levels")
1-plogis(1.32)

print ("Probability of OSV order with adverbial clause")
1-plogis(-1.43)

```


## Interpretation of model 2:

Let's look at the output of random effect first. It has a term called Std.Dev that is nothing but the standard deviation. Generally, GLMM estimates the variation of random effects around the intercept. This variation is provided in terms of standard deviation.

The standard deviation of the verb is 0.75 and EO_ES is 0. Both values are less compared to the value of intercept which 1.32. When the standard deviation is lesser than the intercept, then the random effect doesn't have great influence with the response variable. Especially it is 0 for EO_ES and this indicates that there is no variation for EO/ES with the word order. In other words, it doesn't have any affect with the word order. The another reason is that the proportion of EO and ES in the dataset is not fair. The count of ES is very high (1319 data points) and EO is very very less (93 data points) as well as not all the verbs are having EO attribute. Due to the unbalanced proportion, EO_ES is unable to contribute as random effect. The variation of verb is 0.75 and it is not very lesser than the intercept. This means the verb has a little influence towards the word order, though it is not very high.

This model has a high significant intercept. Predictors such as adverbial clause, adverbial phrase, participle noun clause and special verbal participle are normal significant (*). All these are having negative log odds meaning they have negative effect towards word order. The SOV observation decreases when these factors are increasing.
Predictors such as syllable of subject and syllable of object are highly significant (***). When the syllable of subject increases, the odds of observing SOV increases and when the syllable of object increases, the SOV decreases. 

The probability of SOV is 79% and OSV is 21% with the reference levels. The probability of SOV for adverbial clause is 19%. This model interprets that when the verb is conditioned on the word order, then only the lengthy subject has a great tendency towards SOV. The adverbial clause and lengthy object has a great tendency towards OSV. But the overall probability is again high for SOV and low for OSV.

The main thing to be noted here is, the subject syllable, object syllable and adverbial clause are still holding their effect even after adding the verb. But the verbal participle doesn't have any significant influence when the verb is added.


## Plotting the predictions of model 2 using ggplot

```{r}

tamil.psych.verb.df$pred_model2 <- predict(tamil.psych.verb.glmm, type = "response")


ggplot(tamil.psych.verb.df, aes(x = ID, y = Word_order1, group = 1)) + 
  geom_point(aes(color = "red")) +
  geom_smooth(aes(y=pred_model2, color = "green")) +
  labs(x = "no. of data", y = "actual vs predict values")

```

Model 2 also shows that average probability of SOV is above 50%.

## Evaluation of model 2

```{r}

print ("C value with random effect")
somers2(tamil.psych.verb.df$pred_model2, tamil.psych.verb.df$Word_order1)

print ("C value without random effect")
tamil.psych.verb.df$pred_wo_model2 <- predict(tamil.psych.verb.glmm, type = "response", re.form = NA)
somers2(tamil.psych.verb.df$pred_wo_model2, tamil.psych.verb.df$Word_order1)

```

The C values for both with and without random effects are 0.9. It means the model discriminates well in both cases. 


# Loading and updating the non-psych verb dataset

## 1. Loading the annotation file into R 

```{r}

tamil.non.psych.verb.df <- read.csv2(file.choose())

```

## 2. Removing the unwanted columns

```{r}

tamil.non.psych.verb.df <- select(tamil.non.psych.verb.df, -c(Sentence, Case_of_subject_inTamil, Case_of_object_inTamil, Psych))

```


## 3. Removing white spaces from the column values

```{r}

tamil.non.psych.verb.df <- mutate_if(tamil.non.psych.verb.df, is.character, str_trim)

```
 

## 4. Updating the column values of 'Case_of_object' column

 
```{r}

tamil.non.psych.verb.df <- mutate(tamil.non.psych.verb.df, Case_of_object = replace(Case_of_object, Case_of_object == 'accusative (phrasal)','accusative'))

tamil.non.psych.verb.df <- mutate(tamil.non.psych.verb.df, Case_of_object = replace(Case_of_object, Case_of_object == 'locative (phrasal)','locative'))

tamil.non.psych.verb.df <- mutate(tamil.non.psych.verb.df, Case_of_object = replace(Case_of_object, Case_of_object %in% c("special verbal participle 'endru'", "special verbal participle 'aaga'", "special verbal participle 'patri'","special verbal participle 'ena'"),'special verbal participle'))


```
 
 
```{r}

table (tamil.non.psych.verb.df$Case_of_object)

```


## 5. Converting all the character columns as well as ID column into factors 

```{r}

tamil.non.psych.verb.df <- tamil.non.psych.verb.df %>% mutate_if(is.character, as.factor) %>% mutate_at(c('ID'), as.factor)

```

## 6. Converting integer column values into logarithmic values by adding new columns

```{r}

tamil.non.psych.verb.df <- mutate(tamil.non.psych.verb.df, log_syllable_subject = log(Syllable_of_subject), log_syllable_object = log(Syllable_of_object))

```


## 7. Checking the structure of the dataframe

```{r}

str(tamil.non.psych.verb.df)

```

```{r}

summary (tamil.non.psych.verb.df)

```

## 8. Checking the no. of data for SOV and OSV order

```{r}

table (tamil.non.psych.verb.df$Word_order)

```

## 9. Displaying the word order frequency in bar chart

```{r}

ggplot(tamil.non.psych.verb.df, aes(x = Word_order)) +
  geom_bar(stat = "count", aes(fill = Word_order)) +
  labs(x = "word order", y = "Frequency of word order")

```


## 10. Checking the word order against the syllabe of subject and object

```{r}
 
tamil.non.psych.verb.df %>% group_by(Word_order) %>% summarise(across(c(Syllable_of_subject, Syllable_of_object), mean))

```


# Model 3: GLMM for non-psych verbs

 
## Creating model 3


```{r}

tamil.non.psych.verb.glmm <- glmer(Word_order ~ Case_of_subject + Case_of_object + log_syllable_subject + log_syllable_object + (1 | Verb), family ="binomial", data = tamil.non.psych.verb.df)

```

The 'tamil.non.psych.verb.glmm' is the GLMM for non-psych verbs. It consists of 1 random effect component and fixed effects such as  (1 | Verb) and Case_of_subject + Case_of_object + log_syllable_subject + log_syllable_object respectively. There is no ES and EO for non-psych and so, EO/ES is excluded in this model.


```{r}

summary (tamil.non.psych.verb.glmm)

```

Calculating the probabilities of SOV and OSV for non-psych verbs

```{r}

print ("Probability of SOV order with reference levels")
plogis(1.63)

print ("Probability of OSV order with reference levels")
1-plogis(1.63)

```


Let's look at the output of random effect. The standard deviation of the verb is 0.16 that is very less compared to the intercept which is 1.63. Since the variation of verb is far lesser than the intercept, the verb has almost no influence towards the word order (not even minimum influence). This might be owing to the fact that there are only 2 non-psych verbs. Perhaps if the verbs are more, they might have descent variability.

The intercept is highly significant. Only 2 predictors namely syllable subject and syllable object are significant. Syllable subject has positive slope and syllable object has negative slope. Here also, the lengthy syllable of subject prefers SOV and lengthy syllable of object prefers OSV. 

The probability of SOV is 84% and OSV is 16% with the reference levels nominative subject and accusative object. For non-psych verbs also, the overall probability is high for SOV and low for OSV. 


## Plotting the predictions of model 3 using ggplot

```{r}

tamil.non.psych.verb.df <- mutate(tamil.non.psych.verb.df, Word_order1 = ifelse(Word_order =='SOV', 1, 0))

tamil.non.psych.verb.df$pred <- predict(tamil.non.psych.verb.glmm, type = "response")


ggplot(tamil.non.psych.verb.df, aes(x = ID, y = Word_order1, group = 1)) + 
  geom_point(aes(color = "red")) +
  geom_smooth(aes(y=pred, color = "yellow")) +
  labs(x = "no. of data", y = "actual vs predict values")

```

Model 3 shows that average probability of SOV is above 60% !

## Evaluation of model 3

```{r}

print ("C value with random effect")
somers2(tamil.non.psych.verb.df$pred, tamil.non.psych.verb.df$Word_order1)

print ("C value without random effect")
tamil.non.psych.verb.df$pred_wo <- predict(tamil.non.psych.verb.glmm, type = "response", re.form = NA)
somers2(tamil.non.psych.verb.df$pred_wo, tamil.non.psych.verb.df$Word_order1)

```

The C value with random effect is 0.8 and without random effect is 0.7. Yet there is not much difference between these values, the discrimination of the model is little bit higher with random effect. But, both values are not outstanding. Therefore, the model fit is acceptable and it is not so good. This is due to the reason that the data for non-psych is very small (just 399 data points). However, the dataset of psych verbs is comparatively large and thus those models are having a good fit. Most of the times, model is not effective when the dataset is small. It should be reasonably large in order to analyse it through models.  

