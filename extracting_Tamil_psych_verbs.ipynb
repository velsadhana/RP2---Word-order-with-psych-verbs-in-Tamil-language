{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Extracting sentences from corpus"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"gu4_7nN4PH8l"},"outputs":[],"source":["# Step1: Importing libraries\n","\n","import pandas as pd\n","import numpy as np\n","import glob\n","import os"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Step 2: Reading Tamil corpus (from Uni Leipzig) into pandas dataframe\n","\n","# Downloading all Tamil corpora from the corpus bank of Leipzig university. https://wortschatz.uni-leipzig.de/en/download/Tamil#tam_newscrawl_2011 .\n","# Saving the corpora files in our local machine\n","\n","# Reading all the files into pandas dataframe\n","path = \"C:\\SadhanaOldlaptop\\Velsadhana\\Masterscourse\\Linguistics Data Science\\Sum sem 2023\\Research project 2\\Input files\"\n","datasets = glob.glob(os.path.join(path, \"*.txt\"))     \n","all_df = (pd.read_csv(ds,sep=\"\\t\", header=None,quoting=3,names=[\"ID\", \"Sentence\"]) for ds in datasets)\n","\n","# Concatenating them into a single big dataframe\n","tamil_df = pd.concat(all_df, ignore_index=True)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Removing one sentence which contains error\n","\n","tamil_df = tamil_df[(tamil_df.Sentence.str.contains('தவிர, ·பத்வா கிடங்குகளிலிருந்து'))== False]"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9620,"status":"ok","timestamp":1674742068493,"user":{"displayName":"Claudia Roch","userId":"16953407561906352922"},"user_tz":-60},"id":"Ajq77vDXFV4A","outputId":"38d037c5-cb49-4f96-b34e-f44ac6a3d6c6"},"outputs":[],"source":["# Step 3: Searching the sentences containing the below 10 Tamil psych verbs\n","\n","# Verb 1: Searching sentences from the corpus containing verb 'விய'(viya) - to wonder \n","\n","verb_to_wonder_lst = []\n","for i in tamil_df[\"Sentence\"]:\n","    #temp = ' '.join(i.split()[-2:])\n","    temp = i.split()[-1]\n","    if 'வியந்' in temp or 'வியப்' in temp or 'வியக்' in temp or 'வியத்' in temp:\n","        verb_to_wonder_lst.append(i)\n","\n","verb_to_wonder = pd.DataFrame(verb_to_wonder_lst)\n","\n","# Saving the list in excel format in our local path\n","verb_to_wonder.to_excel('verb_to_wonder.xlsx')\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Verb 2: Searching sentences containing verb 'மகிழ்'(magizh) - to be happy\n","\n","verb_to_be_happy_lst = []\n","for i in tamil_df[\"Sentence\"]:\n","    #temp = ' '.join(i.split()[-2:])\n","    temp = i.split()[-1]\n","    if 'மகிழ்' in temp or 'மகிழு' in temp:\n","        verb_to_be_happy_lst.append(i)\n","\n","verb_to_be_happy = pd.DataFrame(verb_to_be_happy_lst)\n","\n","# Saving the file in our local path\n","verb_to_be_happy.to_excel('verb_to_be_happy.xlsx')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Verb 3: Searching sentences containing verb 'விரும்பு'(virumbu) - to like\n","\n","#verb_to_like = tamil_df[(tamil_df.Sentence.str.contains(' விரும்'))]\n","\n","verb_to_like_lst = []\n","for i in tamil_df[\"Sentence\"]:\n","    temp = i.split()[-1]\n","    if 'விரும்' in temp:\n","        verb_to_like_lst.append(i)\n","\n","verb_to_like = pd.DataFrame(verb_to_like_lst)\n","\n","# Saving the file in our local path\n","verb_to_like.to_excel('verb_to_like.xlsx')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Verb 4: Searching sentences containing verb 'களி'(kali) - to ecstasize\n","\n","verb_to_ecstasize_lst = []\n","for i in tamil_df[\"Sentence\"]:\n","    temp = i.split()[-1]\n","    #if 'களித்' in temp or 'களிப்' in temp or 'களிக்' in temp:\n","    if temp.startswith('களித்') or temp.startswith('களிப்') or temp.startswith('களிக்'):\n","        verb_to_ecstasize_lst.append(i)\n","\n","verb_to_ecstasize = pd.DataFrame(verb_to_ecstasize_lst)\n","\n","# Saving the file in our local path\n","verb_to_ecstasize.to_excel('verb_to_ecstasize.xlsx')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Verb 5: Searching sentences containing verb 'நெகிழ்'(negizh) - to delight\n","\n","verb_to_delight_lst = []\n","for i in tamil_df[\"Sentence\"]:\n","    temp = i.split()[-1]\n","    if 'நெகிழ்' in temp or 'நெகிழு' in temp:\n","        verb_to_delight_lst.append(i)\n","\n","verb_to_delight = pd.DataFrame(verb_to_delight_lst)\n","\n","# Saving the file in our local path\n","verb_to_delight.to_excel('verb_to_delight.xlsx')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Verb 6: Searching sentences containing verb 'அஞ்சு'(anju) - to fear\n","\n","verb_to_fear_lst = []\n","for i in tamil_df[\"Sentence\"]:\n","    temp = i.split()[-1]\n","    if 'அஞ்சி' in temp or 'அச்சு' in temp or 'அஞ்சு' in temp:\n","        verb_to_fear_lst.append(i)\n","\n","verb_to_fear = pd.DataFrame(verb_to_fear_lst)\n","\n","# Saving the file in our local path\n","verb_to_fear.to_excel('verb_to_fear.xlsx')"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Verb 7: Searching sentences containing verb 'திகை' (thigai) - to shock\n","\n","#verb_to_shock = tamil_df[(tamil_df.Sentence.str.contains(' திகைத்')) |  (tamil_df.Sentence.str.contains(' அதிர்'))]\n","\n","verb_to_shock_lst = []\n","for i in tamil_df[\"Sentence\"]:\n","    temp = i.split()[-1]\n","    if 'திகை' in temp:\n","        verb_to_shock_lst.append(i)\n","\n","verb_to_shock = pd.DataFrame(verb_to_shock_lst)\n","\n","# Saving the file in our local path\n","verb_to_shock.to_excel('verb_to_shock.xlsx')"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Verb 8: Searching sentences containing verb தவி (thavi) - to suffer\n","\n","verb_to_suffer_lst = []\n","for i in tamil_df[\"Sentence\"]:\n","    temp = i.split()[-1]\n","    if 'தவித்' in temp or 'தவிக்' in temp or 'தவிப்' in temp:\n","        verb_to_suffer_lst.append(i)\n","\n","verb_to_suffer = pd.DataFrame(verb_to_suffer_lst)\n","\n","# Saving the file in our local path\n","verb_to_suffer.to_excel('verb_to_suffer.xlsx')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Verb 9: Searching sentences containing verb 'வருந்து'(varundhu) - to be sad\n","\n","verb_to_be_sad_lst = []\n","for i in tamil_df[\"Sentence\"]:\n","    temp = i.split()[-1]\n","    if 'வருந்' in temp or 'வருத்' in temp:\n","        verb_to_be_sad_lst.append(i)\n","\n","verb_to_be_sad = pd.DataFrame(verb_to_be_sad_lst)\n","\n","# Saving the file in our local path\n","verb_to_be_sad.to_excel('verb_to_be_sad.xlsx')"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Verb 10: Searching sentences containing verb 'வெறு'(veru) - to hate\n","\n","verb_to_hate_lst = []\n","for i in tamil_df[\"Sentence\"]:\n","    temp = i.split()[-1]\n","    if 'வெறு' in temp:\n","        verb_to_hate_lst.append(i)\n","\n","verb_to_hate = pd.DataFrame(verb_to_hate_lst)\n","\n","# Saving the file in our local path\n","verb_to_hate.to_excel('verb_to_hate.xlsx')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Step 4: Searching the sentences containing the below 2 Tamil non-psych verbs\n","\n","# Non-psych verb 1: Searching sentences containing verb 'படி'(padi) - to read\n","\n","verb_to_read_lst = []\n","for i in tamil_df[\"Sentence\"]:\n","    temp = i.split()[-1]\n","    if 'படித்' in temp or 'படிக்' in temp or 'படிப்' in temp:\n","        verb_to_read_lst.append(i)\n","\n","verb_to_read_non_psych = pd.DataFrame(verb_to_read_lst)\n","\n","# Saving the file in our local path\n","verb_to_read_non_psych.to_excel('verb_to_read_non_psych.xlsx')\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Non-psych verb 2: Searching sentences containing verb 'தேடு'(thaedu) - to search\n","\n","verb_to_search_lst = []\n","for i in tamil_df[\"Sentence\"]:\n","    temp = i.split()[-1]\n","    if 'தேடு' in temp or 'தேடி' in temp:\n","        verb_to_search_lst.append(i)\n","\n","verb_to_search_non_psych = pd.DataFrame(verb_to_search_lst)\n","\n","# Saving the file in our local path\n","verb_to_search_non_psych.to_excel('verb_to_search_non_psych.xlsx')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Concatenating the annotation spreadsheet for first 6 verbs"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Step 1: Concatenating the annotated excel files\n","\n","# Loading the excel files from local path.\n","path2 = \"C:\\SadhanaOldlaptop\\Velsadhana\\Masterscourse\\Linguistics Data Science\\Sum sem 2023\\Research project 2\\Annotation spreadsheet\"                  \n","xl_file_names = glob.glob(os.path.join(path2, \"*.xlsx\"))     \n","xl_files = (pd.read_excel(file) for file in xl_file_names)\n","\n","# Concatenating into single excel file\n","concat_xl_df = pd.concat(xl_files, ignore_index=True)\n","# Saving the concatenated df in local path\n","concat_xl_df.to_excel('annotation_tamil.xlsx')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMxs8Iz/X//zAVtcJAnD8Hb","mount_file_id":"1-aPQOr8vSz0ZgSlf-LPxwI2si5BuIaZF","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}
